<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>技术/AI/笔记 on LX 知识库</title><link>https://namejlt.github.io/categories/%E6%8A%80%E6%9C%AF/ai/%E7%AC%94%E8%AE%B0/</link><description>Recent content in 技术/AI/笔记 on LX 知识库</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Thu, 22 May 2025 18:00:00 +0800</lastBuildDate><atom:link href="https://namejlt.github.io/categories/%E6%8A%80%E6%9C%AF/ai/%E7%AC%94%E8%AE%B0/index.xml" rel="self" type="application/rss+xml"/><item><title>AI 笔记-本地大模型部署</title><link>https://namejlt.github.io/posts/tech/ai/note/local-llm/</link><pubDate>Thu, 22 May 2025 18:00:00 +0800</pubDate><guid>https://namejlt.github.io/posts/tech/ai/note/local-llm/</guid><description>
&lt;h2 id="概述">概述&lt;/h2>
&lt;p>本文主要简述本地部署大模型以及使用。&lt;/p>
&lt;p>本地部署大模型不仅可以保护数据隐私，还能降低API调用成本，减少网络延迟，并且在离线环境中使用。本文将详细介绍多种本地部署大模型的方法、步骤、验证过程以及适用场景，帮助读者成功在本地环境中运行自己的大语言模型。&lt;/p></description></item></channel></rss>