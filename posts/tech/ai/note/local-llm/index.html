<!doctype html><html lang=zh data-figures class=page><head><title>AI 笔记-本地大模型部署 | LX 知识库</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta name=description content="概述
本文主要简述本地部署大模型以及使用。
本地部署大模型不仅可以保护数据隐私，还能降低API调用成本，减少网络延迟，并且在离线环境中使用。本文将详细介绍多种本地部署大模型的方法、步骤、验证过程以及适用场景，帮助读者成功在本地环境中运行自己的大语言模型。"><meta name=twitter:card content="summary"><meta name=twitter:creator content><meta name=twitter:title content="AI 笔记-本地大模型部署"><meta name=twitter:image content="https://namejlt.github.io/"><meta property="og:url" content="https://namejlt.github.io/posts/tech/ai/note/local-llm/"><meta property="og:title" content="AI 笔记-本地大模型部署"><meta property="og:description" content="概述
本文主要简述本地部署大模型以及使用。
本地部署大模型不仅可以保护数据隐私，还能降低API调用成本，减少网络延迟，并且在离线环境中使用。本文将详细介绍多种本地部署大模型的方法、步骤、验证过程以及适用场景，帮助读者成功在本地环境中运行自己的大语言模型。"><meta property="og:image" content="https://namejlt.github.io/"><meta name=keywords content="AI,大模型"><link rel=apple-touch-icon sizes=180x180 href=https://namejlt.github.io/icons/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=https://namejlt.github.io/icons/favicon-32x32.png><link rel=manifest href=https://namejlt.github.io/icons/site.webmanifest><link rel=canonical href=https://namejlt.github.io/posts/tech/ai/note/local-llm/><link rel=preload href=https://namejlt.github.io/css/styles.dc38388a8f0b890e788bd3a99b7495d14e7d5ac4359ed3b49abeb778497863b284ad4cc7e496ef58c84139295f9bafed82f5a41345eda86bd2d429cccb7c2596.css integrity="sha512-3Dg4io8LiQ54i9Opm3SV0U59WsQ1ntO0mr63eEl4Y7KErUzH5JbvWMhBOSlfm6/tgvWkE0XtqGvS1CnMy3wllg==" as=style crossorigin=anonymous><link rel=preload href=https://namejlt.github.io/zh/js/bundle.69325906ed33af5dc7368bca8e00939b95d01580847ca88772bf66270e14fb40adff431f178da9149d66c61d7dcb12f9db4aabf2273327b03c5ddfc5424b4d5e.js as=script integrity="sha512-aTJZBu0zr13HNovKjgCTm5XQFYCEfKiHcr9mJw4U+0Ct/0MfF42pFJ1mxh19yxL520qr8iczJ7A8Xd/FQktNXg==" crossorigin=anonymous><link rel=stylesheet type=text/css href=https://namejlt.github.io/css/styles.dc38388a8f0b890e788bd3a99b7495d14e7d5ac4359ed3b49abeb778497863b284ad4cc7e496ef58c84139295f9bafed82f5a41345eda86bd2d429cccb7c2596.css integrity="sha512-3Dg4io8LiQ54i9Opm3SV0U59WsQ1ntO0mr63eEl4Y7KErUzH5JbvWMhBOSlfm6/tgvWkE0XtqGvS1CnMy3wllg==" crossorigin=anonymous></head><body data-code=100 data-lines=false id=documentTop data-lang=zh><header class=nav_header><nav class=nav><a href=https://namejlt.github.io/ class="nav_brand nav_item" title="LX 知识库">LX 知识库<div class=nav_close><div><svg class="icon"><title>open-menu</title><use xlink:href="#open-menu"/></svg>
<svg class="icon"><title>closeme</title><use xlink:href="#closeme"/></svg></div></div></a><div class='nav_body nav_body_left'><div class=nav_parent><a href=https://namejlt.github.io/posts/ class=nav_item title=文章>文章</a></div><div class=nav_parent><a href=https://namejlt.github.io/tags/ class=nav_item title=标签>标签</a></div><div class=follow><div class=color_mode><input type=checkbox class=color_choice id=mode></div></div></div></nav></header><main><div class="grid-inverse wrap content"><article class=post_content><h1 class=post_title>AI 笔记-本地大模型部署</h1><div class=post_meta><span><svg class="icon"><title>calendar</title><use xlink:href="#calendar"/></svg>
</span><span class=post_date>May 22, 2025
</span><span class=post_time>· 7 分钟阅读</span><span>&nbsp;· <a href=https://namejlt.github.io/tags/ai/ title=AI class="post_tag button button_translucent">AI
</a><a href=https://namejlt.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/ title=大模型 class="post_tag button button_translucent">大模型
</a></span><span class=page_only>&nbsp;·<div class=post_share>分享到:
<a href="https://twitter.com/intent/tweet?text=AI%20%e7%ac%94%e8%ae%b0-%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%83%a8%e7%bd%b2&url=https%3a%2f%2fnamejlt.github.io%2fposts%2ftech%2fai%2fnote%2flocal-llm%2f&tw_p=tweetbutton" class=twitter title="分享到 Twitter" target=_blank rel=nofollow><svg class="icon"><title>twitter</title><use xlink:href="#twitter"/></svg>
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fnamejlt.github.io%2fposts%2ftech%2fai%2fnote%2flocal-llm%2f&t=AI%20%e7%ac%94%e8%ae%b0-%e6%9c%ac%e5%9c%b0%e5%a4%a7%e6%a8%a1%e5%9e%8b%e9%83%a8%e7%bd%b2" class=facebook title="分享到 Facebook" target=_blank rel=nofollow><svg class="icon"><title>facebook</title><use xlink:href="#facebook"/></svg>
</a><a href=#linkedinshare id=linkedinshare class=linkedin title="分享到 LinkedIn" rel=nofollow><svg class="icon"><title>linkedin</title><use xlink:href="#linkedin"/></svg>
</a><a href=https://namejlt.github.io/posts/tech/ai/note/local-llm/ title="Copy Link" class="link link_yank"><svg class="icon"><title>copy</title><use xlink:href="#copy"/></svg></a></div></span></div><div class=post_toc><h2>文章目录</h2><nav id=TableOfContents><ul><li><a href=#概述>概述</a></li><li><a href=#本地部署大模型的优势>本地部署大模型的优势</a></li><li><a href=#硬件要求>硬件要求</a></li><li><a href=#多种部署方式对比>多种部署方式对比</a><ul><li><a href=#1-独立应用程序>1. 独立应用程序</a></li><li><a href=#2-python框架>2. Python框架</a></li><li><a href=#3-docker容器>3. Docker容器</a></li><li><a href=#4-api服务器>4. API服务器</a></li></ul></li><li><a href=#详细部署步骤>详细部署步骤</a><ul><li><a href=#方法一使用ollama部署简单快速>方法一：使用Ollama部署（简单快速）</a></li><li><a href=#方法二使用langchain和hugging-face部署灵活可定制>方法二：使用LangChain和Hugging Face部署（灵活可定制）</a></li><li><a href=#方法三使用docker和text-generation-webui部署功能全面>方法三：使用Docker和text-generation-webui部署（功能全面）</a></li></ul></li><li><a href=#模型量化与优化>模型量化与优化</a><ul><li><a href=#gptq量化>GPTQ量化</a></li><li><a href=#ggmlgguf格式>GGML/GGUF格式</a></li></ul></li><li><a href=#部署验证>部署验证</a><ul><li><a href=#基础功能测试>基础功能测试</a></li><li><a href=#性能测试>性能测试</a></li><li><a href=#稳定性测试>稳定性测试</a></li></ul></li><li><a href=#常见问题与解决方案>常见问题与解决方案</a><ul><li><a href=#内存不足>内存不足</a></li><li><a href=#模型加载缓慢>模型加载缓慢</a></li><li><a href=#生成质量问题>生成质量问题</a></li></ul></li><li><a href=#本地大模型的应用场景>本地大模型的应用场景</a><ul><li><a href=#个人助手>个人助手</a></li><li><a href=#开发辅助>开发辅助</a></li><li><a href=#数据分析>数据分析</a></li><li><a href=#企业内部应用>企业内部应用</a></li></ul></li><li><a href=#进阶模型微调>进阶：模型微调</a><ul><li><a href=#lora微调>LoRA微调</a></li></ul></li><li><a href=#总结>总结</a></li><li><a href=#参考资源>参考资源</a></li></ul></nav></div><div class=post_body><h2 id=概述>概述</h2><p>本文主要简述本地部署大模型以及使用。</p><p>本地部署大模型不仅可以保护数据隐私，还能降低API调用成本，减少网络延迟，并且在离线环境中使用。本文将详细介绍多种本地部署大模型的方法、步骤、验证过程以及适用场景，帮助读者成功在本地环境中运行自己的大语言模型。</p><h2 id=本地部署大模型的优势>本地部署大模型的优势</h2><ol><li><strong>数据隐私与安全</strong>：敏感数据不需要发送到第三方服务器</li><li><strong>降低成本</strong>：避免按token计费的API调用费用</li><li><strong>减少延迟</strong>：无需网络传输，响应更快</li><li><strong>离线使用</strong>：不依赖互联网连接</li><li><strong>自定义与控制</strong>：可以根据需求调整和优化模型（非必要不微调）</li></ol><h2 id=硬件要求>硬件要求</h2><p>在开始部署前，需要了解不同规模模型的硬件需求：</p><table><thead><tr><th>模型规模</th><th>参数量</th><th>最低内存要求</th><th>推荐GPU</th><th>CPU可行性</th><th>应用场景</th></tr></thead><tbody><tr><td>小型模型</td><td>1-3B</td><td>8GB RAM</td><td>4GB VRAM</td><td>可行但较慢</td><td>个人demo</td></tr><tr><td>中型模型</td><td>7-13B</td><td>16GB RAM</td><td>8-16GB VRAM</td><td>勉强可行</td><td>个人使用</td></tr><tr><td>大型模型</td><td>30-70B</td><td>32GB+ RAM</td><td>24GB+ VRAM</td><td>不推荐</td><td>企业应用</td></tr></tbody></table><h2 id=多种部署方式对比>多种部署方式对比</h2><h3 id=1-独立应用程序>1. 独立应用程序</h3><p><strong>代表工具</strong>：LM Studio, Ollama, LocalAI</p><p><strong>优点</strong>：</p><ul><li>用户友好，安装简单</li><li>图形界面操作</li><li>预配置多种模型</li></ul><p><strong>缺点</strong>：</p><ul><li>自定义能力有限</li><li>集成到其他应用可能受限</li></ul><h3 id=2-python框架>2. Python框架</h3><p><strong>代表工具</strong>：LangChain, llama.cpp, Hugging Face Transformers</p><p><strong>优点</strong>：</p><ul><li>高度灵活和可定制</li><li>可与现有Python项目集成</li><li>支持更多高级功能</li></ul><p><strong>缺点</strong>：</p><ul><li>需要编程知识</li><li>配置过程较复杂</li></ul><h3 id=3-docker容器>3. Docker容器</h3><p><strong>代表工具</strong>：text-generation-webui, LocalAI Docker</p><p><strong>优点</strong>：</p><ul><li>环境隔离，避免依赖冲突</li><li>跨平台兼容性好</li><li>易于分发和部署</li></ul><p><strong>缺点</strong>：</p><ul><li>需要Docker知识</li><li>资源消耗略高</li></ul><h3 id=4-api服务器>4. API服务器</h3><p><strong>代表工具</strong>：vLLM, FastAPI+Transformers</p><p><strong>优点</strong>：</p><ul><li>可扩展性强</li><li>多应用共享同一模型实例</li><li>适合团队使用</li></ul><p><strong>缺点</strong>：</p><ul><li>配置复杂</li><li>需要更多系统资源</li></ul><h2 id=详细部署步骤>详细部署步骤</h2><p>下面将介绍几种最常用的部署方法的详细步骤：</p><h3 id=方法一使用ollama部署简单快速>方法一：使用Ollama部署（简单快速）</h3><p>Ollama是一个轻量级工具，可以轻松在本地运行各种开源大语言模型。</p><h4 id=安装步骤>安装步骤</h4><p><strong>MacOS安装</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>curl -fsSL https://ollama.com/install.sh | sh
</span></span></code></pre></div><p><strong>Windows安装</strong>：</p><ul><li>从<a href=https://ollama.com/download>Ollama官网</a>下载安装包</li><li>运行安装程序并按照提示完成安装</li></ul><p><strong>Linux安装</strong>：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>curl -fsSL https://ollama.com/install.sh | sh
</span></span></code></pre></div><h4 id=拉取并运行模型>拉取并运行模型</h4><ol><li>拉取模型（以Llama 2为例）：</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>ollama pull llama2
</span></span></code></pre></div><ol start=2><li>运行模型：</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>ollama run llama2
</span></span></code></pre></div><ol start=3><li>在终端中直接与模型对话</li></ol><h4 id=通过api使用>通过API使用</h4><p>Ollama启动后会在本地运行一个API服务器，可以通过HTTP请求与模型交互：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>curl -X POST http://localhost:11434/api/generate -d <span style=color:#e6db74>&#39;{
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span><span style=color:#e6db74>  &#34;model&#34;: &#34;llama2&#34;,
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3</span><span><span style=color:#e6db74>  &#34;prompt&#34;: &#34;用Python写一个简单的Web服务器&#34;
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4</span><span><span style=color:#e6db74>}&#39;</span>
</span></span></code></pre></div><h3 id=方法二使用langchain和hugging-face部署灵活可定制>方法二：使用LangChain和Hugging Face部署（灵活可定制）</h3><p>这种方法适合有Python基础的用户，提供更多自定义选项。</p><h4 id=安装依赖>安装依赖</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>pip install langchain huggingface_hub transformers torch accelerate bitsandbytes
</span></span></code></pre></div><h4 id=创建python脚本>创建Python脚本</h4><p>创建一个名为<code>local_llm.py</code>的文件：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span><span style=color:#f92672>from</span> langchain.llms <span style=color:#f92672>import</span> HuggingFacePipeline
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span><span style=color:#f92672>from</span> langchain.prompts <span style=color:#f92672>import</span> PromptTemplate
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span><span style=color:#f92672>from</span> langchain.chains <span style=color:#f92672>import</span> LLMChain
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoTokenizer, AutoModelForCausalLM, pipeline
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span><span style=color:#75715e># 加载模型和分词器</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span>model_id <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;THUDM/chatglm3-6b&#34;</span>  <span style=color:#75715e># 可替换为其他模型</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span>tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(model_id)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span>model <span style=color:#f92672>=</span> AutoModelForCausalLM<span style=color:#f92672>.</span>from_pretrained(
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11</span><span>    model_id,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12</span><span>    torch_dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float16,  <span style=color:#75715e># 使用半精度浮点数以减少内存使用</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13</span><span>    device_map<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;auto&#34;</span>,  <span style=color:#75715e># 自动选择设备</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14</span><span>    load_in_8bit<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>,  <span style=color:#75715e># 8位量化以减少内存使用</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15</span><span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17</span><span><span style=color:#75715e># 创建文本生成管道</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18</span><span>pipe <span style=color:#f92672>=</span> pipeline(
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19</span><span>    <span style=color:#e6db74>&#34;text-generation&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20</span><span>    model<span style=color:#f92672>=</span>model,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21</span><span>    tokenizer<span style=color:#f92672>=</span>tokenizer,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">22</span><span>    max_new_tokens<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">23</span><span>    temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0.7</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">24</span><span>    top_p<span style=color:#f92672>=</span><span style=color:#ae81ff>0.95</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">25</span><span>    repetition_penalty<span style=color:#f92672>=</span><span style=color:#ae81ff>1.15</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">26</span><span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">27</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">28</span><span><span style=color:#75715e># 创建LangChain包装器</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">29</span><span>local_llm <span style=color:#f92672>=</span> HuggingFacePipeline(pipeline<span style=color:#f92672>=</span>pipe)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">30</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">31</span><span><span style=color:#75715e># 创建提示模板</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">32</span><span>template <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">33</span><span><span style=color:#e6db74>问题: </span><span style=color:#e6db74>{question}</span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">34</span><span><span style=color:#e6db74>
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">35</span><span><span style=color:#e6db74>回答:
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">36</span><span><span style=color:#e6db74>&#34;&#34;&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">37</span><span>prompt <span style=color:#f92672>=</span> PromptTemplate(template<span style=color:#f92672>=</span>template, input_variables<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;question&#34;</span>])
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">38</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">39</span><span><span style=color:#75715e># 创建LLM链</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">40</span><span>llm_chain <span style=color:#f92672>=</span> LLMChain(prompt<span style=color:#f92672>=</span>prompt, llm<span style=color:#f92672>=</span>local_llm)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">41</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">42</span><span><span style=color:#75715e># 使用模型回答问题</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">43</span><span>question <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;解释一下量子计算的基本原理&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">44</span><span>response <span style=color:#f92672>=</span> llm_chain<span style=color:#f92672>.</span>run(question)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">45</span><span>print(response)
</span></span></code></pre></div><h4 id=运行脚本>运行脚本</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>python local_llm.py
</span></span></code></pre></div><h3 id=方法三使用docker和text-generation-webui部署功能全面>方法三：使用Docker和text-generation-webui部署（功能全面）</h3><p>text-generation-webui是一个功能丰富的Web界面，支持多种模型和高级功能。</p><h4 id=安装docker>安装Docker</h4><p>根据您的操作系统安装Docker：</p><ul><li><a href=https://docs.docker.com/desktop/install/mac-install/>Docker Desktop for Mac</a></li><li><a href=https://docs.docker.com/desktop/install/windows-install/>Docker Desktop for Windows</a></li><li>Linux: <code>curl -fsSL https://get.docker.com | sh</code></li></ul><h4 id=拉取并运行容器>拉取并运行容器</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span>docker run -d <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span><span style=color:#ae81ff></span>  --name text-generation-webui <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3</span><span><span style=color:#ae81ff></span>  -p 7860:7860 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4</span><span><span style=color:#ae81ff></span>  -v ./models:/app/models <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5</span><span><span style=color:#ae81ff></span>  -v ./loras:/app/loras <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6</span><span><span style=color:#ae81ff></span>  -v ./presets:/app/presets <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">7</span><span><span style=color:#ae81ff></span>  --gpus all <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">8</span><span><span style=color:#ae81ff></span>  ghcr.io/oobabooga/text-generation-webui:main
</span></span></code></pre></div><h4 id=下载模型>下载模型</h4><ol><li>访问<code>http://localhost:7860</code>打开Web界面</li><li>点击"Model"选项卡</li><li>在"Download model"部分，选择一个模型（如"THUDM/chatglm3-6b"）并点击下载</li><li>下载完成后，点击"Load"加载模型</li></ol><h4 id=使用web界面>使用Web界面</h4><p>在Web界面中，您可以：</p><ul><li>与模型进行对话</li><li>调整生成参数（温度、top_p等）</li><li>保存和加载对话历史</li><li>使用不同的提示模板</li></ul><h2 id=模型量化与优化>模型量化与优化</h2><p>对于资源有限的设备，可以通过量化技术减少模型大小和内存需求：</p><h3 id=gptq量化>GPTQ量化</h3><p>GPTQ是一种高效的量化方法，可以将模型压缩到4位精度而保持大部分性能。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span><span style=color:#75715e># 使用AutoGPTQ库量化模型</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span>pip install auto-gptq
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoTokenizer
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span><span style=color:#f92672>from</span> auto_gptq <span style=color:#f92672>import</span> AutoGPTQForCausalLM
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4</span><span>model_name <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;TheBloke/Llama-2-7B-GPTQ&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5</span><span>tokenizer <span style=color:#f92672>=</span> AutoTokenizer<span style=color:#f92672>.</span>from_pretrained(model_name)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">6</span><span>model <span style=color:#f92672>=</span> AutoGPTQForCausalLM<span style=color:#f92672>.</span>from_pretrained(model_name, use_safetensors<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><h3 id=ggmlgguf格式>GGML/GGUF格式</h3><p>GGML/GGUF是为CPU推理优化的模型格式，由llama.cpp项目使用：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span><span style=color:#75715e># 安装llama-cpp-python</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span>pip install llama-cpp-python
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span><span style=color:#f92672>from</span> llama_cpp <span style=color:#f92672>import</span> Llama
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span><span style=color:#75715e># 加载GGUF格式模型</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span>llm <span style=color:#f92672>=</span> Llama(
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span>    model_path<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;./models/llama-2-7b.Q4_K_M.gguf&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>    n_ctx<span style=color:#f92672>=</span><span style=color:#ae81ff>4096</span>,  <span style=color:#75715e># 上下文窗口大小</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span>    n_threads<span style=color:#f92672>=</span><span style=color:#ae81ff>8</span>  <span style=color:#75715e># 使用的CPU线程数</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span><span style=color:#75715e># 生成文本</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11</span><span>output <span style=color:#f92672>=</span> llm(<span style=color:#e6db74>&#34;解释一下人工智能的发展历程：&#34;</span>, max_tokens<span style=color:#f92672>=</span><span style=color:#ae81ff>512</span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12</span><span>print(output[<span style=color:#e6db74>&#34;choices&#34;</span>][<span style=color:#ae81ff>0</span>][<span style=color:#e6db74>&#34;text&#34;</span>])
</span></span></code></pre></div><h2 id=部署验证>部署验证</h2><p>成功部署后，应进行以下验证测试：</p><h3 id=基础功能测试>基础功能测试</h3><ol><li><p><strong>简单问答</strong>：测试模型是否能回答基本问题</p><pre tabindex=0><code>问题：什么是机器学习？
</code></pre></li><li><p><strong>上下文理解</strong>：测试模型是否能理解多轮对话上下文</p><pre tabindex=0><code>问题1：我有一只宠物。
问题2：它是什么颜色的？（模型应询问宠物类型或表示信息不足）
</code></pre></li><li><p><strong>指令遵循</strong>：测试模型是否能遵循特定指令</p><pre tabindex=0><code>请用五个词总结人工智能的影响。
</code></pre></li></ol><h3 id=性能测试>性能测试</h3><ol><li><strong>响应时间</strong>：测量从输入到输出的时间</li><li><strong>内存使用</strong>：监控模型运行时的内存占用</li><li><strong>GPU利用率</strong>：检查GPU使用情况（如适用）</li></ol><p>可以使用以下命令监控资源使用：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span><span style=color:#75715e># 监控CPU和内存</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span>top
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">3</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">4</span><span><span style=color:#75715e># 监控GPU（NVIDIA）</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">5</span><span>nvidia-smi -l <span style=color:#ae81ff>1</span>
</span></span></code></pre></div><h3 id=稳定性测试>稳定性测试</h3><ol><li><strong>长时间运行</strong>：让模型持续运行几小时，检查是否出现内存泄漏</li><li><strong>并发请求</strong>：测试同时处理多个请求的能力</li><li><strong>错误恢复</strong>：测试在输入异常情况下的行为</li></ol><h2 id=常见问题与解决方案>常见问题与解决方案</h2><h3 id=内存不足>内存不足</h3><p><strong>症状</strong>：出现"CUDA out of memory"或类似错误</p><p><strong>解决方案</strong>：</p><ul><li>使用更小的模型</li><li>应用量化技术（4位或8位量化）</li><li>减小批处理大小和上下文长度</li><li>使用模型并行或CPU卸载</li></ul><h3 id=模型加载缓慢>模型加载缓慢</h3><p><strong>症状</strong>：模型需要很长时间才能加载完成</p><p><strong>解决方案</strong>：</p><ul><li>使用SSD而非HDD存储模型</li><li>预先将模型转换为适合的格式（如GGUF）</li><li>使用模型缓存</li></ul><h3 id=生成质量问题>生成质量问题</h3><p><strong>症状</strong>：回答质量差或不相关</p><p><strong>解决方案</strong>：</p><ul><li>调整生成参数（温度、top_p等）</li><li>优化提示模板</li><li>尝试不同的模型</li><li>增加上下文信息</li></ul><h2 id=本地大模型的应用场景>本地大模型的应用场景</h2><h3 id=个人助手>个人助手</h3><ul><li><strong>知识管理</strong>：整理和总结个人笔记和文档</li><li><strong>创意写作</strong>：辅助写作文章、故事或代码</li><li><strong>学习辅助</strong>：解释复杂概念，回答学习问题</li></ul><h3 id=开发辅助>开发辅助</h3><ul><li><strong>代码生成与调试</strong>：生成代码片段，解释代码，提供调试建议</li><li><strong>API文档生成</strong>：自动生成项目文档</li><li><strong>需求分析</strong>：帮助分析和澄清项目需求</li></ul><h3 id=数据分析>数据分析</h3><ul><li><strong>数据解释</strong>：解释数据趋势和模式</li><li><strong>报告生成</strong>：根据数据自动生成分析报告</li><li><strong>数据清洗建议</strong>：提供数据预处理建议</li></ul><h3 id=企业内部应用>企业内部应用</h3><ul><li><strong>知识库问答</strong>：基于企业内部文档回答问题</li><li><strong>客户服务</strong>：处理常见客户查询</li><li><strong>内部培训</strong>：生成培训材料和测试问题</li></ul><h2 id=进阶模型微调>进阶：模型微调</h2><p>对于特定领域应用，可以考虑对基础模型进行微调：</p><h3 id=lora微调>LoRA微调</h3><p>LoRA（Low-Rank Adaptation）是一种高效的微调方法，只需更新少量参数：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">1</span><span><span style=color:#75715e># 安装PEFT库</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">2</span><span>pip install peft datasets
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 1</span><span><span style=color:#f92672>from</span> peft <span style=color:#f92672>import</span> LoraConfig, get_peft_model
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 2</span><span><span style=color:#f92672>from</span> transformers <span style=color:#f92672>import</span> AutoModelForCausalLM, TrainingArguments, Trainer
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 3</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 4</span><span><span style=color:#75715e># 加载基础模型</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 5</span><span>base_model <span style=color:#f92672>=</span> AutoModelForCausalLM<span style=color:#f92672>.</span>from_pretrained(<span style=color:#e6db74>&#34;THUDM/chatglm3-6b&#34;</span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 6</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 7</span><span><span style=color:#75715e># 配置LoRA</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 8</span><span>lora_config <span style=color:#f92672>=</span> LoraConfig(
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f"> 9</span><span>    r<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>,  <span style=color:#75715e># LoRA的秩</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">10</span><span>    lora_alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">11</span><span>    target_modules<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;query_key_value&#34;</span>],
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">12</span><span>    lora_dropout<span style=color:#f92672>=</span><span style=color:#ae81ff>0.05</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">13</span><span>    bias<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;none&#34;</span>,
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">14</span><span>    task_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;CAUSAL_LM&#34;</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">15</span><span>)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">16</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">17</span><span><span style=color:#75715e># 创建PEFT模型</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">18</span><span>peft_model <span style=color:#f92672>=</span> get_peft_model(base_model, lora_config)
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">19</span><span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">20</span><span><span style=color:#75715e># 设置训练参数并开始训练</span>
</span></span><span style=display:flex><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:.4em;padding:0 .4em;color:#7f7f7f">21</span><span><span style=color:#75715e># ...（此处省略训练代码）</span>
</span></span></code></pre></div><h2 id=总结>总结</h2><p>本地部署大语言模型为个人和组织提供了强大的AI能力，同时保护数据隐私并降低成本。根据您的需求和技术水平，可以选择从简单的Ollama部署到复杂的自定义Python框架或Docker容器。</p><p>无论选择哪种方法，都需要注意硬件要求、模型选择和优化技术。通过适当的量化和参数调整，即使在普通消费级硬件上也能获得良好的性能。</p><p>随着大语言模型技术的不断发展，本地部署将变得更加简单和高效，为更多应用场景提供支持。</p><p>今后，随着大模型技术和硬件技术的进一步发展，本地部署将成为主流选择，为更多应用场景提供支持。</p><h2 id=参考资源>参考资源</h2><ul><li><a href=https://ollama.com/docs>Ollama官方文档</a></li><li><a href=https://huggingface.co/docs/transformers/index>Hugging Face Transformers文档</a></li><li><a href=https://python.langchain.com/docs/get_started/introduction>LangChain文档</a></li><li><a href=https://github.com/ggerganov/llama.cpp>llama.cpp项目</a></li><li><a href=https://github.com/oobabooga/text-generation-webui>text-generation-webui项目</a></li></ul></div><div class=post_comments></div></article><aside class=sidebar><section class=sidebar_inner><br><h2 class=mt-4>最新文章</h2><ul class=flex-column><li><a href=https://namejlt.github.io/posts/tech/readcode/deepwiki/04diy/ class=nav-link title="deepwiki源码阅读-04 修改验证">deepwiki源码阅读-04 修改验证</a></li><li><a href=https://namejlt.github.io/posts/tech/readcode/deepwiki/03core/ class=nav-link title="deepwiki源码阅读-03 核心逻辑分析">deepwiki源码阅读-03 核心逻辑分析</a></li><li><a href=https://namejlt.github.io/posts/tech/readcode/deepwiki/02project/ class=nav-link title="deepwiki源码阅读-02 项目整体分析">deepwiki源码阅读-02 项目整体分析</a></li><li><a href=https://namejlt.github.io/posts/tech/readcode/deepwiki/01start/ class=nav-link title="deepwiki源码阅读-01 开篇">deepwiki源码阅读-01 开篇</a></li><li><a href=https://namejlt.github.io/posts/tech/ai/app-dev/003-ai-code-cursor/ class=nav-link title="AI 应用开发-003 AI辅助编程工具 cursor">AI 应用开发-003 AI辅助编程工具 cursor</a></li><li><a href=https://namejlt.github.io/posts/tech/ai/note/local-llm/ class=nav-link title="AI 笔记-本地大模型部署">AI 笔记-本地大模型部署</a></li><li><a href=https://namejlt.github.io/posts/tech/ai/app-dev/002-prompt/ class=nav-link title="AI 应用开发-002 PROMPT 提示词">AI 应用开发-002 PROMPT 提示词</a></li><li><a href=https://namejlt.github.io/posts/tech/ai/app-dev/001-api-function-call/ class=nav-link title="AI 应用开发-001 API Function Call">AI 应用开发-001 API Function Call</a></li></ul><div><h2 class="mt-4 taxonomy" id=categories-section>分类</h2><nav class=tags_nav><a href=https://namejlt.github.io/categories/%E6%8A%80%E6%9C%AF/ai/%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/ class="post_tag button button_translucent" title=技术/ai/应用开发>技术/AI/应用开发
<span class=button_tally>4</span>
</a><a href=https://namejlt.github.io/categories/%E6%8A%80%E6%9C%AF/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/deepwiki/ class="post_tag button button_translucent" title=技术/源码阅读/deepwiki>技术/源码阅读/DEEPWIKI
<span class=button_tally>4</span>
</a><a href=https://namejlt.github.io/categories/%E6%8A%80%E6%9C%AF/ai/%E7%AC%94%E8%AE%B0/ class="post_tag button button_translucent" title=技术/ai/笔记>技术/AI/笔记
<span class=button_tally>1</span>
</a><a href=https://namejlt.github.io/categories/%E6%8A%80%E6%9C%AF/%E5%AE%9E%E8%B7%B5/%E5%90%8E%E7%AB%AF/ class="post_tag button button_translucent" title=技术/实践/后端>技术/实践/后端
<span class=button_tally>1</span>
</a><a href=https://namejlt.github.io/categories/%E6%8A%80%E6%9C%AF/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/hugo/ class="post_tag button button_translucent" title=技术/源码阅读/hugo>技术/源码阅读/HUGO
<span class=button_tally>1</span></a></nav></div><div><h2 class="mt-4 taxonomy" id=tags-section>标签</h2><nav class=tags_nav><a href=https://namejlt.github.io/tags/ai/ class="post_tag button button_translucent" title=ai>AI
<span class=button_tally>5</span>
</a><a href=https://namejlt.github.io/tags/%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/ class="post_tag button button_translucent" title=源码阅读>源码阅读
<span class=button_tally>5</span>
</a><a href=https://namejlt.github.io/tags/deepwiki/ class="post_tag button button_translucent" title=deepwiki>DEEPWIKI
<span class=button_tally>4</span>
</a><a href=https://namejlt.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/ class="post_tag button button_translucent" title=大模型>大模型
<span class=button_tally>4</span>
</a><a href=https://namejlt.github.io/tags/%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/ class="post_tag button button_translucent" title=应用开发>应用开发
<span class=button_tally>4</span>
</a><a href=https://namejlt.github.io/tags/cursor/ class="post_tag button button_translucent" title=cursor>CURSOR
<span class=button_tally>1</span>
</a><a href=https://namejlt.github.io/tags/hugo/ class="post_tag button button_translucent" title=hugo>HUGO
<span class=button_tally>1</span>
</a><a href=https://namejlt.github.io/tags/prompt/ class="post_tag button button_translucent" title=prompt>PROMPT
<span class=button_tally>1</span>
</a><a href=https://namejlt.github.io/tags/%E5%90%8E%E7%AB%AF/ class="post_tag button button_translucent" title=后端>后端
<span class=button_tally>1</span></a></nav></div></section></aside></div></main><svg width="0" height="0" class="hidden"><symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="facebook"><path d="M437 0H75C33.648.0.0 33.648.0 75v362c0 41.352 33.648 75 75 75h151V331h-60v-90h60v-61c0-49.629 40.371-90 90-90h91v90h-91v61h91l-15 90h-76v181h121c41.352.0 75-33.648 75-75V75c0-41.352-33.648-75-75-75zm0 0"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18.001 18.001" id="twitter"><path d="M15.891 4.013c.808-.496 1.343-1.173 1.605-2.034a8.68 8.68.0 01-2.351.861c-.703-.756-1.593-1.14-2.66-1.14-1.043.0-1.924.366-2.643 1.078A3.56 3.56.0 008.766 5.383c0 .309.039.585.117.819-3.076-.105-5.622-1.381-7.628-3.837-.34.601-.51 1.213-.51 1.846.0 1.301.549 2.332 1.645 3.089-.625-.053-1.176-.211-1.645-.47.0.929.273 1.705.82 2.388a3.623 3.623.0 002.115 1.291c-.312.08-.641.118-.979.118-.312.0-.533-.026-.664-.083.23.757.664 1.371 1.291 1.841a3.652 3.652.0 002.152.743C4.148 14.173 2.625 14.69.902 14.69c-.422.0-.721-.006-.902-.038 1.697 1.102 3.586 1.649 5.676 1.649 2.139.0 4.029-.542 5.674-1.626 1.645-1.078 2.859-2.408 3.639-3.974a10.77 10.77.0 001.172-4.892v-.468a7.788 7.788.0 001.84-1.921 8.142 8.142.0 01-2.11.593z"/></symbol><symbol aria-hidden="true" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="mail"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V4e2c0 26.5-21.5 48-48 48H48c-26.5.0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5.0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="calendar"><path d="M452 40h-24V0h-40v40H124V0H84v40H60C26.916 40 0 66.916.0 1e2v352c0 33.084 26.916 60 60 60h392c33.084.0 60-26.916 60-60V1e2c0-33.084-26.916-60-60-60zm20 412c0 11.028-8.972 20-20 20H60c-11.028.0-20-8.972-20-20V188h432v264zm0-304H40v-48c0-11.028 8.972-20 20-20h24v40h40V80h264v40h40V80h24c11.028.0 20 8.972 20 20v48z"/><path d="M76 230h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zM76 310h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zM76 390h40v40H76zm80 0h40v40h-40zm80 0h40v40h-40zm80 0h40v40h-40zm80-80h40v40h-40z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="github"><path d="M255.968 5.329C114.624 5.329.0 120.401.0 262.353c0 113.536 73.344 209.856 175.104 243.872 12.8 2.368 17.472-5.568 17.472-12.384.0-6.112-.224-22.272-.352-43.712-71.2 15.52-86.24-34.464-86.24-34.464-11.616-29.696-28.416-37.6-28.416-37.6-23.264-15.936 1.728-15.616 1.728-15.616 25.696 1.824 39.2 26.496 39.2 26.496 22.848 39.264 59.936 27.936 74.528 21.344 2.304-16.608 8.928-27.936 16.256-34.368-56.832-6.496-116.608-28.544-116.608-127.008.0-28.064 9.984-51.008 26.368-68.992-2.656-6.496-11.424-32.64 2.496-68 0 0 21.504-6.912 70.4 26.336 20.416-5.696 42.304-8.544 64.096-8.64 21.728.128 43.648 2.944 64.096 8.672 48.864-33.248 70.336-26.336 70.336-26.336 13.952 35.392 5.184 61.504 2.56 68 16.416 17.984 26.304 40.928 26.304 68.992.0 98.72-59.84 120.448-116.864 126.816 9.184 7.936 17.376 23.616 17.376 47.584.0 34.368-.32 62.08-.32 70.496.0 6.88 4.608 14.88 17.6 12.352C438.72 472.145 512 375.857 512 262.353 512 120.401 397.376 5.329 255.968 5.329z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 212 212" id="gitlab"><path d="M12.3 74.7h54L43.3 3c-1-3.6-6.4-3.6-7.6.0L12.3 74.8z"/><path d="M12.3 74.7.5 111c-1 3.2.0 6.8 3 8.8l101.6 74-92.5-119z"/><path d="M105 193.7l-38.6-119h-54l92.7 119z"/><path d="M105 193.7l38.7-119H66.4l38.7 119z"/><path d="M105 193.7l38.7-119H198l-93 119z"/><path d="M198 74.7l11.6 36.2c1 3 0 6.6-3 8.6l-101.5 74 93-119z"/><path d="M198 74.7h-54.3L167 3c1.2-3.6 6.4-3.6 7.6.0L198 74.8z"/></symbol><symbol viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" id="rss"><circle cx="3.429" cy="20.571" r="3.429"/><path d="M11.429 24h4.57C15.999 15.179 8.821 8.001.0 8v4.572c6.302.001 11.429 5.126 11.429 11.428z"/><path d="M24 24C24 10.766 13.234.0.0.0v4.571c10.714.0 19.43 8.714 19.43 19.429z"/></symbol><symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="linkedin"><path d="M437 0H75C33.648.0.0 33.648.0 75v362c0 41.352 33.648 75 75 75h362c41.352.0 75-33.648 75-75V75c0-41.352-33.648-75-75-75zM181 406h-60V196h60zm0-240h-60v-60h60zm210 240h-60V286c0-16.54-13.46-30-30-30s-30 13.46-30 30v120h-60V196h60v11.309C286.719 202.422 296.93 196 316 196c40.691.043 75 36.547 75 79.688zm0 0"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 612 612" id="to-top"><path d="M604.501 440.509 325.398 134.956c-5.331-5.357-12.423-7.627-19.386-7.27-6.989-.357-14.056 1.913-19.387 7.27L7.499 440.509c-9.999 10.024-9.999 26.298.0 36.323s26.223 10.024 36.222.0l262.293-287.164L568.28 476.832c9.999 10.024 26.222 10.024 36.221.0 9.999-10.023 9.999-26.298.0-36.323z"/></symbol><symbol viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" id="carly"><path d="M504.971 239.029 448 182.059V84c0-46.317-37.682-84-84-84h-44c-13.255.0-24 10.745-24 24s10.745 24 24 24h44c19.851.0 36 16.149 36 36v108c0 6.365 2.529 12.47 7.029 16.971L454.059 256l-47.029 47.029A24.002 24.002.0 004e2 320v108c0 19.851-16.149 36-36 36h-44c-13.255.0-24 10.745-24 24s10.745 24 24 24h44c46.318.0 84-37.683 84-84v-98.059l56.971-56.971c9.372-9.372 9.372-24.568.0-33.941zM112 192V84c0-19.851 16.149-36 36-36h44c13.255.0 24-10.745 24-24S205.255.0 192 0h-44c-46.318.0-84 37.683-84 84v98.059l-56.971 56.97c-9.373 9.373-9.373 24.568.0 33.941L64 329.941V428c0 46.317 37.682 84 84 84h44c13.255.0 24-10.745 24-24s-10.745-24-24-24h-44c-19.851.0-36-16.149-36-36V320c0-6.365-2.529-12.47-7.029-16.971L57.941 256l47.029-47.029A24.002 24.002.0 00112 192z"/></symbol><symbol viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" id="copy"><path d="M23 2.75A2.75 2.75.0 0020.25.0H8.75A2.75 2.75.0 006 2.75v13.5A2.75 2.75.0 008.75 19h11.5A2.75 2.75.0 0023 16.25zM18.25 14.5h-7.5a.75.75.0 010-1.5h7.5a.75.75.0 010 1.5zm0-3h-7.5a.75.75.0 010-1.5h7.5a.75.75.0 010 1.5zm0-3h-7.5a.75.75.0 010-1.5h7.5a.75.75.0 010 1.5z"/><path d="M8.75 20.5A4.255 4.255.0 014.5 16.25V2.75c0-.086.02-.166.025-.25H3.75A2.752 2.752.0 001 5.25v16A2.752 2.752.0 003.75 24h12a2.752 2.752.0 002.75-2.75v-.75z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512.001 512.001" id="closeme"><path d="M284.286 256.002 506.143 34.144c7.811-7.811 7.811-20.475.0-28.285-7.811-7.81-20.475-7.811-28.285.0L256 227.717 34.143 5.859c-7.811-7.811-20.475-7.811-28.285.0-7.81 7.811-7.811 20.475.0 28.285l221.857 221.857L5.858 477.859c-7.811 7.811-7.811 20.475.0 28.285a19.938 19.938.0 0014.143 5.857 19.94 19.94.0 0014.143-5.857L256 284.287l221.857 221.857c3.905 3.905 9.024 5.857 14.143 5.857s10.237-1.952 14.143-5.857c7.811-7.811 7.811-20.475.0-28.285L284.286 256.002z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" id="open-menu"><path d="M492 236H20c-11.046.0-20 8.954-20 20s8.954 20 20 20h472c11.046.0 20-8.954 20-20s-8.954-20-20-20zm0-160H20C8.954 76 0 84.954.0 96s8.954 20 20 20h472c11.046.0 20-8.954 20-20s-8.954-20-20-20zm0 320H20c-11.046.0-20 8.954-20 20s8.954 20 20 20h472c11.046.0 20-8.954 20-20s-8.954-20-20-20z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="instagram"><path d="M12 2.163c3.204.0 3.584.012 4.85.07 3.252.148 4.771 1.691 4.919 4.919.058 1.265.069 1.645.069 4.849.0 3.205-.012 3.584-.069 4.849-.149 3.225-1.664 4.771-4.919 4.919-1.266.058-1.644.07-4.85.07-3.204.0-3.584-.012-4.849-.07-3.26-.149-4.771-1.699-4.919-4.92-.058-1.265-.07-1.644-.07-4.849.0-3.204.013-3.583.07-4.849.149-3.227 1.664-4.771 4.919-4.919 1.266-.057 1.645-.069 4.849-.069zM12 0C8.741.0 8.333.014 7.053.072c-4.358.2-6.78 2.618-6.98 6.98-.059 1.281-.073 1.689-.073 4.948s.014 3.668.072 4.948c.2 4.358 2.618 6.78 6.98 6.98C8.333 23.986 8.741 24 12 24s3.668-.014 4.948-.072c4.354-.2 6.782-2.618 6.979-6.98.059-1.28.073-1.689.073-4.948s-.014-3.667-.072-4.947c-.196-4.354-2.617-6.78-6.979-6.98-1.281-.059-1.69-.073-4.949-.073zm0 5.838c-3.403.0-6.162 2.759-6.162 6.162S8.597 18.163 12 18.163s6.162-2.759 6.162-6.163c0-3.403-2.759-6.162-6.162-6.162zM12 16c-2.209.0-4-1.79-4-4 0-2.209 1.791-4 4-4s4 1.791 4 4c0 2.21-1.791 4-4 4zm6.406-11.845c-.796.0-1.441.645-1.441 1.44s.645 1.44 1.441 1.44c.795.0 1.439-.645 1.439-1.44s-.644-1.44-1.439-1.44z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="youtube"><path d="M19.615 3.184c-3.604-.246-11.631-.245-15.23.0-3.897.266-4.356 2.62-4.385 8.816.029 6.185.484 8.549 4.385 8.816 3.6.245 11.626.246 15.23.0C23.512 20.55 23.971 18.196 24 12c-.029-6.185-.484-8.549-4.385-8.816zM9 16V8l8 3.993L9 16z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="stackoverflow"><path d="M21 27v-8h3v11H0V19h3v8h18z"/><path d="M17.1.2 15 1.8l7.9 10.6 2.1-1.6L17.1.2zm3.7 14.7L10.6 6.4l1.7-2 10.2 8.5-1.7 2zM7.2 12.3l12 5.6 1.1-2.4-12-5.6-1.1 2.4zm-1.8 6.8 13.56 1.96.17-2.38-13.26-2.55-.47 2.97zM19 25H5v-3h14v3z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" id="xing"><path d="M18.188.0c-.517.0-.741.325-.927.66.0.0-7.455 13.224-7.702 13.657.015.024 4.919 9.023 4.919 9.023.17.308.436.66.967.66h3.454c.211.0.375-.078.463-.22.089-.151.089-.346-.009-.536l-4.879-8.916c-.004-.006-.004-.016.0-.022L22.139.756c.095-.191.097-.387.006-.535C22.056.078 21.894.0 21.686.0h-3.498zM3.648 4.74c-.211.0-.385.074-.473.216-.09.149-.078.339.02.531l2.34 4.05c.004.01.004.016.0.021L1.86 16.051c-.099.188-.093.381.0.529.085.142.239.234.45.234h3.461c.518.0.766-.348.945-.667l3.734-6.609-2.378-4.155c-.172-.315-.434-.659-.962-.659H3.648v.016z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 71 55" id="discord"><path d="M60.1045 4.8978C55.5792 2.8214 50.7265 1.2916 45.6527.41542 45.5603.39851 45.468.440769 45.4204.525289 44.7963 1.6353 44.105 3.0834 43.6209 4.2216c-5.4572-.817-10.8864-.817-16.2317.0C26.905 3.0581 26.1886 1.6353 25.5617.525289 25.5141.443589 25.4218.40133 25.3294.41542c-5.071.87338-9.9237 2.40318-14.4518 4.48238C10.8384 4.9147 10.8048 4.9429 10.7825 4.9795 1.57795 18.7309-.943561 32.1443.293408 45.3914.299005 45.4562.335386 45.5182.385761 45.5576 6.45866 50.0174 12.3413 52.7249 18.1147 54.5195 18.2071 54.5477 18.305 54.5139 18.3638 54.4378 19.7295 52.5728 20.9469 50.6063 21.9907 48.5383 22.0523 48.4172 21.9935 48.2735 21.8676 48.2256 19.9366 47.4931 18.0979 46.6 16.3292 45.5858 16.1893 45.5041 16.1781 45.304 16.3068 45.2082 16.679 44.9293 17.0513 44.6391 17.4067 44.3461 17.471 44.2926 17.5606 44.2813 17.6362 44.3151c11.6196 5.3051 24.1992 5.3051 35.6817.0C53.3935 44.2785 53.4831 44.2898 53.5502 44.3433 53.9057 44.6363 54.2779 44.9293 54.6529 45.2082 54.7816 45.304 54.7732 45.5041 54.6333 45.5858c-1.7687 1.0339-3.6074 1.9073-5.5412 2.637C48.9662 48.2707 48.9102 48.4172 48.9718 48.5383c1.0662 2.0651 2.2836 4.0316 3.6241 5.8967C52.6519 54.5139 52.7526 54.5477 52.845 54.5195c5.8014-1.7946 11.684-4.5021 17.7569-8.9619C70.6551 45.5182 70.6887 45.459 70.6943 45.3942 72.1747 30.0791 68.2147 16.7757 60.1968 4.9823 60.1772 4.9429 60.1437 4.9147 60.1045 4.8978zM23.7259 37.3253c-3.4983.0-6.3808-3.2117-6.3808-7.156s2.8266-7.156 6.3808-7.156c3.5821.0 6.4367 3.2399 6.3807 7.156.0 3.9443-2.8266 7.156-6.3807 7.156zm23.5919.0c-3.4982.0-6.3807-3.2117-6.3807-7.156s2.8265-7.156 6.3807-7.156c3.5822.0 6.4367 3.2399 6.3808 7.156.0 3.9443-2.7986 7.156-6.3808 7.156z"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 17 18" id="mastodon"><path fill="#fff" d="m15.054695 9.8859583c-.22611 1.1632697-2.02517 2.4363497-4.09138 2.6830797-1.0774504.12856-2.1382704.24673-3.2694704.19484-1.84996-.0848-3.30971-.44157-3.30971-.44157.0.1801.0111.35157.0333.51194.24051 1.82571 1.81034 1.93508 3.29737 1.98607 1.50088.0514 2.8373104-.37004 2.8373104-.37004l.0617 1.35686s-1.0498104.56374-2.9199404.66742c-1.03124.0567-2.3117-.0259-3.80308-.42069-3.23454998-.85613-3.79081998-4.304-3.87592998-7.8024197-.026-1.03871-.01-2.01815-.01-2.83732.0-3.57732 2.34385998-4.62587996 2.34385998-4.62587996 1.18184-.54277 3.20976-.77101 5.318-.7882499985409h.0518C9.8267646.01719834 11.856025.24547834 13.037775.78824834c0 0 2.34377 1.04855996 2.34377 4.62587996.0.0.0294 2.63937-.32687 4.47183"/><path fill="#000" d="m12.616925 5.6916583v4.3315297h-1.71607V5.8189683c0-.88624-.37289-1.33607-1.1187604-1.33607-.82467.0-1.23799.53361-1.23799 1.58875v2.30122h-1.70594v-2.30122c0-1.05514-.4134-1.58875-1.23808-1.58875-.74587.0-1.11876.44983-1.11876 1.33607v4.2042197h-1.71607V5.6916583c0-.88527.22541-1.58876.67817-2.10922.46689-.52047 1.07833-.78727 1.83735-.78727.87816.0 1.54317.33752 1.98288 1.01267l.42744.71655.42753-.71655c.43961-.67515 1.10463-1.01267 1.9828704-1.01267.75893.0 1.37037.2668 1.83735.78727.45268.52046.67808 1.22395.67808 2.10922"/></symbol><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 600 530" id="bluesky"><path d="m135.72 44.03C202.216 93.951 273.74 195.17 3e2 249.49c26.262-54.316 97.782-155.54 164.28-205.46C512.26 8.009 590-19.862 590 68.825c0 17.712-10.155 148.79-16.111 170.07-20.703 73.984-96.144 92.854-163.25 81.433 117.3 19.964 147.14 86.092 82.697 152.22-122.39 125.59-175.91-31.511-189.63-71.766-2.514-7.3797-3.6904-10.832-3.7077-7.8964-.0174-2.9357-1.1937.51669-3.7077 7.8964-13.714 40.255-67.233 197.36-189.63 71.766-64.444-66.128-34.605-132.26 82.697-152.22-67.108 11.421-142.55-7.4491-163.25-81.433-5.9562-21.282-16.111-152.36-16.111-170.07.0-88.687 77.742-60.816 125.72-24.795z"/><symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 48 48" id="ko-fi"><path fill="#fff" d="M4.5 9.8527H32.7947a0 0 0 010 0v19.225a9.07 9.07.0 01-9.07 9.07H13.57a9.07 9.07.0 01-9.07-9.07V9.8527a0 0 0 010 0z"/><path fill="#000" d="M12.197 25.9493l6.45 6.45 6.45-6.45a8.2 8.2.0 002.4016-5.798h0a4.5082 4.5082.0 00-4.212-4.5459 4.4262 4.4262.0 00-4.64 4.4209 4.4261 4.4261.0 00-4.64-4.4209 4.5082 4.5082.0 00-4.212 4.5459h0a8.2 8.2.0 002.4024 5.798z"/><path fill="#fff" d="M32.7947 9.8527H35.73a7.77 7.77.0 010 15.5394H32.7947"/></svg></symbol></svg><footer class=footer><div class="footer_inner wrap pale"><img src=https://namejlt.github.io/icons/apple-touch-icon.png class="icon icon_2 transparent" alt="LX 知识库"><p>Copyright&nbsp;<span class=year></span>&nbsp;LX 知识库. All Rights Reserved</p><a class=to_top href=#documentTop><svg class="icon"><title>to-top</title><use xlink:href="#to-top"/></svg></a></div></footer><script type=text/javascript src=https://namejlt.github.io/zh/js/bundle.69325906ed33af5dc7368bca8e00939b95d01580847ca88772bf66270e14fb40adff431f178da9149d66c61d7dcb12f9db4aabf2273327b03c5ddfc5424b4d5e.js integrity="sha512-aTJZBu0zr13HNovKjgCTm5XQFYCEfKiHcr9mJw4U+0Ct/0MfF42pFJ1mxh19yxL520qr8iczJ7A8Xd/FQktNXg==" crossorigin=anonymous></script></body></html>